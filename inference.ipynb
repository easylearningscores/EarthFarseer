{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import json\n",
    "from typing import Any\n",
    "import torch\n",
    "import pickle\n",
    "import logging\n",
    "import numpy as np\n",
    "from model import Fourier_Model\n",
    "from tqdm import tqdm\n",
    "from API import dataloader\n",
    "from utils import *\n",
    "from timeit import default_timer\n",
    "import torch\n",
    "import os\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import random\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tester:\n",
    "    def __init__(self, model, test_loader, path):\n",
    "        self.model = model\n",
    "        self.test_loader = test_loader\n",
    "        self.path = path\n",
    "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    def load_checkpoint(self, checkpoint_path):\n",
    "        with open(checkpoint_path, 'rb') as f:\n",
    "            buffer = io.BytesIO(f.read())\n",
    "        \n",
    "        checkpoint = torch.load(buffer)\n",
    "        self.model.load_state_dict(checkpoint)\n",
    "        self.model.to(self.device)\n",
    "\n",
    "    def test(self, checkpoint_path):\n",
    "        self.load_checkpoint(checkpoint_path) \n",
    "        self.model.eval()\n",
    "        inputs_lst, trues_lst, preds_lst = [], [], []\n",
    "        for batch_x, batch_y in self.test_loader:\n",
    "            pred_y, x_rec = self.model(batch_x.to(self.device))\n",
    "\n",
    "\n",
    "            list(map(lambda data, lst: lst.append(data.detach().cpu().numpy()), [\n",
    "                 batch_x, batch_y, pred_y], [inputs_lst, trues_lst, preds_lst]))\n",
    "        inputs, trues, preds = map(lambda data: np.concatenate(\n",
    "            data, axis=0), [inputs_lst, trues_lst, preds_lst])\n",
    "\n",
    "        folder_path = self.path+'/results/{}/sv/'\n",
    "        if not os.path.exists(folder_path):\n",
    "            os.makedirs(folder_path)\n",
    "        # 计算RMSE\n",
    "        rmse = torch.sqrt(torch.mean((torch.tensor(preds) - torch.tensor(trues)) ** 2))\n",
    "        rmse = rmse.item()\n",
    "        \n",
    "        for np_data in ['inputs', 'trues', 'preds']:\n",
    "            np.save(osp.join(folder_path, np_data + '.npy'), vars()[np_data])\n",
    "        return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "\n",
    "class TaxiBJDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, input_data, output_data):\n",
    "        self.input_data = input_data\n",
    "        self.output_data = output_data\n",
    "        self.mean = np.mean(input_data)\n",
    "        self.std = np.std(input_data)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.input_data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        input_sample = self.input_data[idx]\n",
    "        output_sample = self.output_data[idx]\n",
    "        \n",
    "        # normalize the input and output samples\n",
    "        #input_sample = (input_sample - self.mean) / self.std\n",
    "        #output_sample = (output_sample - self.mean) / self.std\n",
    "        \n",
    "        input_sample = torch.from_numpy(input_sample).to(torch.float32)\n",
    "        output_sample = torch.from_numpy(output_sample).to(torch.float32)\n",
    "        return input_sample[:,:,::4,::4], output_sample\n",
    "    \n",
    "\n",
    "def load_data(batch_size, val_batch_size, data_root, num_workers):\n",
    "\n",
    "    train_input_data = np.load(data_root + 'TaxiBJ/train_input_data_reshaped.npy')\n",
    "    train_output_data = np.load(data_root + 'TaxiBJ/train_output_data_reshaped.npy')\n",
    "    # train_input_data = train_input_data.reshape(3555, 12, 2, 128, 128)\n",
    "    # train_output_data = train_output_data.reshape(3555, 12, 2, 128, 128)\n",
    "\n",
    "\n",
    "    test_input_data = np.load(data_root + 'TaxiBJ/test_input_data_reshaped.npy')\n",
    "    test_output_data = np.load(data_root + 'TaxiBJ/test_output_data_reshaped.npy')\n",
    "    # test_input_data = test_input_data.reshape(445, 12, 2, 128, 128)\n",
    "    # test_output_data = test_output_data.reshape(445, 12, 2, 128, 128)\n",
    "    \n",
    "\n",
    "    val_input_data = np.load(data_root+'TaxiBJ/val_input_data_reshaped.npy')\n",
    "    val_output_data = np.load(data_root+'TaxiBJ/val_output_data_reshaped.npy')\n",
    "    # val_input_data = val_input_data.reshape(444, 12, 2, 128, 128)\n",
    "    # val_output_data = val_output_data.reshape(444, 12, 2, 128, 128)\n",
    "\n",
    "    train_set = TaxiBJDataset(train_input_data, train_output_data)\n",
    "    test_set = TaxiBJDataset(test_input_data, test_output_data)\n",
    "    val_set = TaxiBJDataset(val_input_data, val_output_data)\n",
    "\n",
    "    dataloader_train = DataLoader(train_set, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=num_workers)\n",
    "    dataloader_test = DataLoader(test_set, batch_size=val_batch_size, shuffle=False, pin_memory=True, num_workers=num_workers)\n",
    "    dataloader_validation = DataLoader(val_set, batch_size=val_batch_size, shuffle=False, pin_memory=True, num_workers=num_workers)\n",
    "\n",
    "    mean, std = 0, 1\n",
    "\n",
    "    return dataloader_train, dataloader_validation, dataloader_test, mean, std\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     dataloader_train, dataloader_validation, dataloader_test, mean, std = load_data(batch_size=1, \n",
    "#                                                                                     val_batch_size=1, \n",
    "#                                                                                     data_root='/data/workspace/yancheng/MM/earthfarseer/data/',\n",
    "#                                                                                     num_workers=8)\n",
    "#     for input_frames, output_frames in iter(dataloader_train):\n",
    "#         print(input_frames.shape, output_frames.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_train, dataloader_validation, dataloader_test, mean, std = load_data(batch_size=1, \n",
    "                                                                                    val_batch_size=1, \n",
    "                                                                                    data_root='/data/workspace/yancheng/MM/earthfarseer/data/',\n",
    "                                                                                    num_workers=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Fourier_Model(shape_in = [12, 2, 128, 128], hid_S=64, hid_T=256, N_S=2, N_T=4, groups=2)\n",
    "\n",
    "test_loader = dataloader_test\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "path = '/data/workspace/yancheng/MM/earthfarseer/results_super_res'\n",
    "\n",
    "tester = Tester(model=model, test_loader=test_loader, path=path)\n",
    "args = argparse.Namespace(checkpoint_path='/data/workspace/yancheng/MM/earthfarseer/results_super_res/results_super_res/checkpoint.pth')\n",
    "mse = tester.test(args.checkpoint_path)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
